{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('teamdf1000games.csv', sep=',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['index', 'Result', 'Rk', 'Date','Tm', 'Opp'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['Tm', 'Opp']\n",
    "#df = pd.get_dummies(df, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.MP.apply(lambda x: x.isnumeric())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ['W/L'] = np.sign(df[\"PTS\"] - df[\"PTS.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PTS'] = df['PTS']/240\n",
    "df['FG'] = df['FG']/240\n",
    "df['FGA'] = df['FGA']/240\n",
    "df['2P'] = df['2P']/240\n",
    "df['2PA'] = df['2PA']/240\n",
    "df['3P'] = df['3P']/240\n",
    "df['3PA'] = df['3PA']/240\n",
    "df['FT'] = df['FT']/240\n",
    "df['FTA'] = df['FTA']/240\n",
    "df['PTS.1'] = df['PTS.1']/240\n",
    "df['FG.1'] = df['FG.1']/240\n",
    "df['FGA.1'] = df['FGA.1']/240\n",
    "df['2P.1'] = df['2P.1']/240\n",
    "df['2PA.1'] = df['2PA.1']/240\n",
    "df['3P.1'] = df['3P.1']/240\n",
    "df['3PA.1'] = df['3PA.1']/240\n",
    "df['FT.1'] = df['FT.1']/240\n",
    "df['FTA.1'] = df['FTA.1']/240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('MP', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('teamdf1000games_cleaned.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['W/L']\n",
    "y = y.values.reshape(1, -1).flatten()\n",
    "\n",
    "X = df.drop(\"W/L\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "#X_std = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LR = LogisticRegression()\n",
    "clf_SVC = SVC(kernel = 'rbf',)\n",
    "clf_XGB = xgb.XGBClassifier(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_XGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    '''\n",
    "    print the accuracy score, classification report and confusion matrix of classifier\n",
    "    '''\n",
    "    if train:\n",
    "        '''\n",
    "        training performance\n",
    "        '''\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, clf.predict(X_train))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, clf.predict(X_train))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, clf.predict(X_train))))\n",
    "\n",
    "        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "        \n",
    "    elif train==False:\n",
    "        '''\n",
    "        test performance\n",
    "        '''\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, clf.predict(X_test))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, clf.predict(X_test))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, clf.predict(X_test))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_LR, X_train, y_train, X_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_LR, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_SVC, X_train, y_train, X_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_SVC, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_XGB, X_train, y_train, X_test, y_test, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(clf_XGB, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('teamdf_playoff_games.csv', sep=',', index_col = 0)\n",
    "\n",
    "df_test.drop(['index', 'Result', 'Rk', 'Date','Tm', 'Opp'], axis=1, inplace= True)\n",
    "#cols = ['Tm', 'Opp']\n",
    "#df = pd.get_dummies(df, columns = cols)\n",
    "\n",
    "df_test = df_test[df_test.MP.apply(lambda x: x.isnumeric())]\n",
    "df_test = df_test.astype(float)\n",
    "df_test ['W/L'] = np.sign(df_test[\"PTS\"] - df_test[\"PTS.1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['PTS'] = df_test['PTS']/240\n",
    "df_test['FG'] = df_test['FG']/240\n",
    "df_test['FGA'] = df_test['FGA']/240\n",
    "df_test['2P'] = df_test['2P']/240\n",
    "df_test['2PA'] = df_test['2PA']/240\n",
    "df_test['3P'] = df_test['3P']/240\n",
    "df['3PA'] = df['3PA']/240\n",
    "df_test['FT'] = df_test['FT']/240\n",
    "df_test['FTA'] = df_test['FTA']/240\n",
    "df_test['PTS.1'] = df_test['PTS.1']/240\n",
    "df_test['FG.1'] = df_test['FG.1']/240\n",
    "df_test['FGA.1'] = df_test['FGA.1']/240\n",
    "df_test['2P.1'] = df_test['2P.1']/240\n",
    "df_test['2PA.1'] = df_test['2PA.1']/240\n",
    "df_test['3P.1'] = df_test['3P.1']/240\n",
    "df_test['3PA.1'] = df_test['3PA.1']/240\n",
    "df_test['FT.1'] = df_test['FT.1']/240\n",
    "df_test['FTA.1'] = df_test['FTA.1']/240\n",
    "\n",
    "df_test = df_test.drop('MP', axis=1)\n",
    "\n",
    "df_test.dropna(axis = 0, inplace=True)\n",
    "\n",
    "#df.to_csv('teamdf1000games_cleaned.csv', sep = ',')\n",
    "\n",
    "y_t = df_test['W/L']\n",
    "y_t = y_t.values.reshape(1, -1).flatten()\n",
    "\n",
    "X_t = df_test.drop(\"W/L\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_std = sc_X.fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Result:\\n\")        \n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_t, clf_LR.predict(X_t))))\n",
    "print(\"Classification Report: \\n {}\\n\".format(classification_report(y_t, clf_LR.predict(X_t))))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_t, clf_LR.predict(X_t))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_t, clf_LR.predict(X_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,16)); \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = [[74,136,.544,73,134,.545,1,2,.5,37,60,.617,186,68,115,.591,67,113,.593,1,2,.5,47,57,.825,184],\n",
    "     [55,98,.561,40,67,.597,15,31,.484,27,29,.931,152,42,91,.462,35,77,.455,7,14,.5,23,31,.742,144],\n",
    "     [54,101,.535,40,72,.556,14,29,.483,30,35,.857,152,57,111,.514,39,73,.534,18,38,.474,17,17,1,149]\n",
    "    ]\n",
    "X_a = sc_X.fit_transform(a)\n",
    "clf_LR.predict(X_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
